{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'candidate_id': 'candidate_raw', 'overall_score': 45, 'scores': {'metrics_achievement': 4, 'action_verbs': 16, 'quantification': 4, 'relevance': 1, 'readability': 20}, 'top_changes': [{'index': 0, 'type': 'added_line', 'summary': 'Professional Summary:'}, {'index': 1, 'type': 'added_line', 'summary': 'Led cross-functional projects and improved operational efficiency by <X>%. Optimized workflows, reduced delays, and collaborated with teams to enhance productivity.'}, {'index': 2, 'type': 'added_line', 'summary': 'Experience:'}, {'index': 3, 'type': 'added_line', 'summary': '- Led a 5-member team to deliver project milestones on time.'}, {'index': 4, 'type': 'added_line', 'summary': '- Improved data processing performance by <Y>% through automated pipelines.'}, {'index': 5, 'type': 'added_line', 'summary': '- Collaborated with stakeholders to identify bottlenecks and implement improvements.'}, {'index': 0, 'type': 'removed_line', 'summary': 'MICHELLE SMITH'}, {'index': 1, 'type': 'removed_line', 'summary': 'email@email.com'}, {'index': 2, 'type': 'removed_line', 'summary': '(541) 754-3010'}, {'index': 3, 'type': 'removed_line', 'summary': '1515 Pacific Ave, CA 90291 Los Angeles'}, {'index': 4, 'type': 'removed_line', 'summary': 'Sant Antonio'}, {'index': 5, 'type': 'removed_line', 'summary': 'American'}], 'changed_lines': [], 'timestamp': '2025-11-24T19:51:34.140406+05:30'}\n"
     ]
    }
   ],
   "source": [
    "# quick test (run in repo root)\n",
    "from agents.evaluator import evaluate_resume\n",
    "orig = open(\"data/extracted.txt\", encoding=\"utf-8\").read()\n",
    "# for now, create a quick mocked rewrite (or reuse data/output/rewritten_resume.txt)\n",
    "rew = open(\"data/output/rewritten_resume.txt\", encoding=\"utf-8\").read()\n",
    "report = evaluate_resume(orig, rew, candidate_id=\"candidate_raw\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.parser import extract_text\n",
    "from agents.rewriter import rewrite_resume\n",
    "from agents.evaluator import evaluate_resume\n",
    "\n",
    "orig = extract_text(\"data/candidate_raw.pdf\")                        # writes data/extracted.txt if needed\n",
    "rew = rewrite_resume(orig)                                           # writes data/output/rewritten_resume.txt\n",
    "report = evaluate_resume(orig, rew, candidate_id=\"candidate_raw\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report overall: 48\n",
      "Saved memory versions: ['candidate_raw__original__20251124T204156.json', 'candidate_raw__rewritten__20251124T204156.json']\n",
      "Files produced in data/output/: ['candidate_raw_report.json', 'rewritten_resume.txt', 'sample_report.json']\n"
     ]
    }
   ],
   "source": [
    "# End-to-end demo cell\n",
    "from agents.parser import extract_text\n",
    "from agents.rewriter import rewrite_resume\n",
    "from agents.evaluator import evaluate_resume\n",
    "from agents.memory import save_version, list_versions\n",
    "from agents.observability import record_metrics\n",
    "from pathlib import Path\n",
    "\n",
    "candidate_pdf = \"data/candidate_raw.pdf\"\n",
    "candidate_id = \"candidate_raw\"\n",
    "\n",
    "# 1) parse (saves data/extracted.txt if your parser writes it)\n",
    "orig_text = extract_text(candidate_pdf)                     \n",
    "\n",
    "# save original to memory\n",
    "save_version(candidate_id, \"original\", orig_text)\n",
    "\n",
    "# 2) rewrite via LLM (or mock fallback)\n",
    "rewritten = rewrite_resume(orig_text)\n",
    "save_version(candidate_id, \"rewritten\", rewritten)\n",
    "\n",
    "# 3) evaluate & record metrics\n",
    "report = evaluate_resume(orig_text, rewritten, candidate_id=candidate_id)\n",
    "record_metrics(candidate_id, report)\n",
    "\n",
    "# 4) quick output check\n",
    "print(\"Report overall:\", report[\"overall_score\"])\n",
    "print(\"Saved memory versions:\", list_versions(candidate_id))\n",
    "print(\"Files produced in data/output/:\", [p.name for p in Path(\"data/output\").iterdir()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
